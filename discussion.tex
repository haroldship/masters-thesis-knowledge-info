% !TEX root = thesis.tex

%%
%%
%% Discussion chapter
%%
%%

%The contribution of this thesis is an empirical statistical analysis of the accuracy of the \gls{dkd}
%as a tool for estimating the incidence risk of chronic diseases.
In this research we studied how different factors of the population and incidence distributions
affect the \textit{accuracy} of the \gls{dkd}.
We examined the effect of several factors on the \gls{dkd} accuracy,
and we measured the accuracy of the \gls{dkd} using \gls{mise},
\gls{miae}, \gls{supremum error}, as well as \gls{peak bias},
\gls{peak drift} and \gls{centroid bias} and \gls{centroid drift},
as described in \Cref{sec:method:accuracy}.
We ran several scenarios to examine how variations in these factors which affect the incidence risk function,
the population distribution, and the sample size affect the accuracy of \gls{dkd} for estimation.
We compared two bandwidth selection techniques, \gls{silverman}'s rule of thumb,
and least-squares \glsentrylong{cv},
both optimized to minimize \gls{mise}.
We also compared these two techniques to an \gls{oracle},
which is an approximation of the theoretical optimal bandwidth,
keeping in mind that the oracle is only computable for simulations because we know the true function we wish to estimate.

Each scenario consisted of a set of experiments,
with each experiment consisting of 1,000 monte carlo simulations.
Each simulation was a random realization of the experimental setup.
In this way,
we obtained empirical estimates of each of the above accuracy measures for the \gls{dkd}
for each bandwidth selection technique.
However,
we found that the computations of each experiment required a lot of time,
and so we tried several methods to reduce this time.
We attempted to speed up the cross-validation bandwidth selection by using gradient descent.
We found the gradient descent algorithm often resulted in severe oversmoothing,
as the cross-validation error would decrease slowly as the bandwidth increased.
This required a lot of manual tuning of the learning rate parameter,
and so required re-running the experiment several times.
We added \textit{momentum} to our gradient descent implementation but it did not help in every case,
and so we changed our strategy to use parallelization as described in \Cref{sec:method:experiment_structure}.

We observed that the estimation errors observed using the \gls{silverman} Rule of Thumb bandwidth selection method
were nearly as good as \gls{cv} in every case.
Since computing the \gls{silverman} bandwidth is much simpler than \gls{cv},
it would seem that using \gls{silverman} is warranted as a preliminary step such as for exploratory analysis.
However,
we note that in \Cref{tab:mean_error_rates:p0.7_100_1.0_1h} the accuracy measure \gls{mise} using the \gls{silverman} rule of thumb is even better than was obtained using the \gls{oracle}.
We tried to run with an additional experiment using 499 monte carlo simulations instead of 49 to compute the oracle bandwidth,
and found that in this case the \gls{silverman} rule did not outperform the \gls{oracle}.

We found that estimating the peak of the true function using the global maximum value can be improved upon.
Our method of using the 5\% centroid gave better results for both the magnitude and location of the peak most of the time.

Our results for those experiments which consist of different \gls{risk} functions on
\textbf{uniform populations},
that is,
for those for which the \gls{dkd} reduces to a kernel intensity estimate
have lower estimation errors than those which estimate
\gls{risk} functions on population distributions with a single peak.
This indicates that the population distribution has a noticeable negative effect on the accuracy of the \gls{dkd}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Section: Limitations
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Limitations}
\label{sec:discussion:limitations}

This study uses simulated data,
sampled from a known ``true'' incidence rate function in order to measure the accuracy of the \gls{dkd} estimator.
This is quite different from what is done in a typical epidemiological study,
where population and incident locations are acquired from such sources as government and medical records,
while the rate is estimated using statistical inference.
This allows us,
in our study,
to precisely compute the measures of accuracy as deviations from the true values,
which cannot be done in scientific studies where the true incidence rate function is not known beforehand.

However,
our population and incidence rate functions,
which allow us to compute the population and incidents at points in the plane,
do not completely represent any actual population or incidents.
Nor is our study area representative of any actual populated area.
Rather,
these simplifications allow us to examine the effects of different attributes of the above functions,
by allowing us to control these factors in different experimental setups.
However,
this means that our results describe the sensitivity of the \gls{dkd} to these factors in general,
but do not provide any guarantees about the accuracy of the \gls{dkd} in any specific study where it has been used.

Another limitation of this study is that we compared only two bandwidth selection techniques.
There are several techniques available that we did not consider,
including adaptive bandwidth selectors which may give better results especially under highly variable population distributions.

Finally,
our experiments studied the randomness associated with incident locations that are sampled from various risk functions in the plane.
However,
due to computational issues,
we used fixed functions in the denominator,
under the assumption that we have enough data to accurately estimate the population density.
This means that we are working under the ideal scenario where there is no uncertainty in estimating the population density.



