% !TEX root = thesis.tex

%%
%%
%% Method chapter
%%
%%

In this chapter, we describe the methods used to examine the statistical performance of the \gls{dkd}.
The basic unit is the \textit{experiment}, a set of simulations run with the same initial setup with the same measurements taken.
There is a fixed setup for each experiment, with the following set of parameters.
\begin{table}[htbp]
    \centering
    \begin{tabular}{ll}
    Parameter name & Description \\
    \hline
    x1.min & Minimum value of the study area in the horizontal (\(X_1\)) direction \\
    x1.max & Maximum value of the study area in the horizontal (\(X_1\)) direction  \\
    x2.min & Minimum value of the study area in the vertical (\(X_2\)) direction \\
    x2.max & Maximum value of the study area in the vertical (\(X_2\)) direction \\
    grid.by & Space between grid points in the study area \\
    buffer & Buffer around outside of study area \\
    N.p & Size of population \\
    EN.i & Expected number of incidents per simulation \\
    c1 & (optional) \(X_1\) coordinate of the population peak \\
    c2 & (optional) \(X_2\) coordinate of the population peak \\
    sigma1 & (optional) \(X_1\) standard deviation of the population peak \\
    sigma2 & (optional) \(X_2\) standard deviation of the population peak \\
    rho & (optional) Correlation coefficient of \(X_1\) and \(X_2\) \\
    bandwidths & List of bandwidths for evaluating the Oracle \\
    incident\textunderscore rate & Risk function for generating incidents from population \\
    \end{tabular}
    \caption{Experimental parameters}
    \label{tab:experimental_parameters}
\end{table}

\Cref{sec:method:experiment_structure} describes the steps of each experiment, together with the measurements taken.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Section: computing the dkd
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Computing the DKD}
\label{sec:method:computing}

The \gls{dkd} is computed over the study area as the ratio of two positive-valued functions.
At any given point \((x_1, x_2)\) in the plane, we can compute \(I(x_1, x_2)\), the \gls{factor} at that point.
We call \(I(x_1, x_2)\) the \textit{incident intensity} at \((x_1, x_2)\).
Next, at the same point, we can compute \(P(x_1, x_2)\), the population \textit{population intensity} at \((x_1, x_2)\).
Ideally, we would know how to compute these functions exactly, and we would then compute \(\lambda(x_1, x_2)\) the risk,
or probability of an incident at \((x_1, x_2)\) with the ratio:
\begin{equation}
    \lambda(x_1, x_2) = \frac{I(x_1, x_2)}{P(x_1, x_2)}.
\end{equation}

Since we assume that we cannot compute \(I(x_1, x_2)\) and \(P(x_1, x_2)\) exactly, we approximate them as follows.

TBD intensity kernel

For simplicity of computation, we do not account for edge effects.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Section: accuracy measures
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Measuring the accuracy of the DKD}
\label{sec:method:accuracy}

In order to describe the accuracy of the \gls{dkd} as a method of estimating the true risk function \(\lambda\),
we use several accuracy measures.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Subsection: MISE
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{MISE}
\label{subsec:method:mise}

\Gls{mise} is a measure of the expected squared difference between an estimated risk function \gls{lambda_hat},
computed using the \gls{dkd}, and the true risk function \gls{lambda}.
\Gls{mise} allows for additional analysis by being broken down into the mean integraged bias and mean integrated variance.
It can also be easily approximated by cross-validation error.

For any given data sample, we can use the \gls{dkd} to compute the estimated risk function \gls{lambda_hat}.
We then integrate the squared error in the estimate over the plane to obtain the \gls{ise}.

\begin{equation}
    \mbox{ISE}(\hat{\lambda}) = 
        \int_{-\infty}^{\infty} \int_{-\infty}^{\infty}
            \left(
                \hat{\lambda}(x_1, x_2) - \lambda(x_1, x_2)
            \right)^2 \diff{x_2} \diff{x_1}
\end{equation}

We can then compute the expected value of the \gls{ise} to obtain the \gls{mise}.

\begin{equation}
    \mbox{MISE} = \E [\mbox{ISE}(\hat{\lambda})]
\end{equation}

In our experiments, we run \(M\) monte carlo simulations, and approximate the \gls{mise} by taking the empirical average of the \glspl{ise}.

\begin{equation}
    \widetilde{\mbox{MISE}} = \frac{1}{M} \sum_{i=1}^{M} \mbox{ISE}(\hat{\lambda_i})
\end{equation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Subsection: Relative and normalized errors
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\subsection{Relative and normalized MISE}
%\label{subsec:method:relative}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Subsection: MIAE
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{MIAE}
\label{subsec:method:miae}

\Gls{miae} is a measure of the expected absolute difference between an estimated risk function \gls{lambda_hat},
computed using the \gls{dkd}, and the true risk function \gls{lambda}.
\Gls{miae} differs from \gls{mise} by on the one hand providing a more intuitive comparison,
since we are comparing the absolute difference instead of the squared difference.
On the other hand, it lacks some of the nice mathematical properties of the \gls{mise}.

As we did in \autoref{subsec:method:mise}, for any given data sample we use the \gls{dkd} to compute the estimated risk function \gls{lambda_hat}.
We then integrate the absolute value of the error in the estimate over the plane to obtain the \gls{ise}.

\begin{equation}
    \mbox{IAE}(\hat{\lambda}) = 
        \int_{-\infty}^{\infty} \int_{-\infty}^{\infty}
            \left|
                \hat{\lambda}(x_1, x_2) - \lambda(x_1, x_2)
            \right| \diff{x_2} \diff{x_1}
\end{equation}

We can then compute the expected value of the \gls{ise} to obtain the \gls{mise}.

\begin{equation}
    \mbox{MIAE} = \E [\mbox{IAE}(\hat{\lambda})]
\end{equation}

As above, we run \(M\) monte carlo simulations, and approximate the \gls{miae} by taking the empirical average of the \glspl{iae}.

\begin{equation}
    \widetilde{\mbox{MIAE}} = \frac{1}{M} \sum_{i=1}^{M} \mbox{IAE}(\hat{\lambda_i})
\end{equation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Subsection: Max error
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Supremum error}
\label{subsec:method:sup_error}

Whereas the previous two measures of accuracy describe how much the estimated intensity deviates from the truth over the whole plane,
the \gls{supremum error} looks at the worst case.
We define the \gls{supremum error} as follows:

\begin{equation}
    \mbox{supremum error}(\hat{\lambda}) = \sup_{(x_1, x_2) \in \RS}
        {\left|
            \hat{\lambda}(x_1, x_2) - \lambda(x_1, x_2)
        \right|}
\end{equation}

As in the previous accuracy measures, we run \(M\) monte carlo simulations, and approximate the \mbox{supremum error}, by taking the empirical average of the supremum error of the estimates.

\begin{equation}
    \widetilde{\mbox{\gls{supremum error}}} = \frac{1}{M} \sum_{i=1}^{M} \mbox{supremum error}(\hat{\lambda_i})
\end{equation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Subsection: Peak bias and drift
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Peak bias and peak drift}
\label{subsec:method:peak_bias}

The next two accuracy measures compare the estimated risk function's accuracy in computing the peak.
The \gls{peak error} is difference between the maximum value of the \gls{dkd} estimate \gls{lambda_hat} and the maximum of the true risk function \gls{lambda}.
We denote by \gls{peak bias} the mean over the monte carlo simulations of the \gls{peak error}.
The \gls{peak bias} gives us a feel for how much the \gls{dkd} tends to over or underestimate the worst case of the true risk \gls{lambda}.

The second measure associated with the peak we call the \gls{peak drift}.
It is defined as the mean distance between the peak of \gls{lambda_hat} and \gls{lambda}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Subsection: Centroid bias and drift
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Centroid bias and peak drift}
\label{subsec:method:centroid_bias}

The final two accuracy measures also compare the estimated risk function's accuracy in computing the peak.
In fact, they are nearly identical to the preceding two accuracy measures.
However, unlike the \gls{peak error} and \gls{peak bias}, they do not use the exact peak of \gls{lambda_hat}.
Instead, they use the centroid and average value of \gls{lambda_hat} over the 5\% of the study area where \gls{lambda_hat} is highest.
We call the corresponding accuracy measures \gls{centroid bias} and \gls{centroid drift}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Section: experiment structure
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experiment structure}
\label{sec:method:experiment_structure}

In order to ensure repeatability of the experiements, we begin by setting the random number seed to the same fixed value (12).

The first step in each experimental run is to define the study area. 
The study area is defined as a 2-dimensional rectangle, with coordinates in the \(x_1\) and \(x_2\) directions set using the parameters \textit{x1.min}, \textit{x1.max}, \textit{x2.min}, and \textit{x2.max}.
These are abstract units of distance, that are analogous to kilometers or miles or any other actual unit of distance in which the \gls{dkd} might be used for spatial analysis.
The study area is further restricted by the \textit{buffer} parameter, which forms a border around the perimeter of the study area.

Next, a population is generated of size \textit{N.p}.
When the \textit{c1} and \textit{c2} parameters are given, the population is distributed according to the parameters above.
In particular, the distribution has bivariate normal shape with center (\textit{c1}, \textit{c2}),
standard deviations \textit{sigma1}, \textit{sigma2}, and correlation \textit{rho}.

Next, we adjust the incident rate function, \(R(x_1, x_2)\) parameter, by scaling it so that the expected number of incidents \gls{mu} is equal to the \textit{EN.i} parameter.
Assuming the expected number of incidents generate by \(f(x_1, x_2)\) by itself is 1, we have

\[
    R((x_1, x_2)) = \gls{mu}~\times~\mbox{incident\textunderscore rate}(x_1, x_2) \text{,}
\]

and we call \(R((x_1, x_2)\) is the \textit{true incident rate} for the experiment.

\section{Verifying bandwidth selection dependency on size}

\section{Effect of expected number of incidents on DKD accuracy}

\section{Effect of sample size on DKD accuracy}

\section{Effect of risk function spread on DKD accuracy}

\section{Effect of population spread on DKD accuracy}

\section{Examining two peaks in the risk function}

\section{Examining non-uniform population distrbution}

