% !TEX root = thesis.tex

%%
%%
%% Method chapter
%%
%%

In this chapter, we describe the methods used to examine the statistical performance of the \gls{dkd}.
The basic unit is the \textit{experiment}, a set of simulations run with the same initial setup with the same measurements taken.
There is a fixed setup for each experiment, with the following set of parameters.
\begin{table}[htbp]
    \centering
    \begin{tabular}{ll}
    Parameter name & Description \\
    \hline
    x1.min & Minimum value of the study area in the horizontal (\(X_1\)) direction \\
    x1.max & Maximum value of the study area in the horizontal (\(X_1\)) direction  \\
    x2.min & Minimum value of the study area in the vertical (\(X_2\)) direction \\
    x2.max & Maximum value of the study area in the vertical (\(X_2\)) direction \\
    grid.by & Space between grid points in the study area \\
    buffer & Buffer around outside of study area \\
    N.p & Size of population \\
    EN.i & Expected number of incidents per simulation \\
    c1 & (optional) \(X_1\) coordinate of the population peak \\
    c2 & (optional) \(X_2\) coordinate of the population peak \\
    sigma1 & (optional) \(X_1\) standard deviation of the population peak \\
    sigma2 & (optional) \(X_2\) standard deviation of the population peak \\
    rho & (optional) Correlation coefficient of \(X_1\) and \(X_2\) \\
    bandwidths & List of bandwidths for evaluating the Oracle \\
    incident\textunderscore rate & Risk function for generating incidents from population \\
    \end{tabular}
    \caption{Experimental parameters}
    \label{tab:experimental_parameters}
\end{table}

\Cref{sec:method:experiment_structure} describes the steps of each experiment, together with the measurements taken.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Section: accuracy measures
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Measuring of accuracy of the DKD}
\label{sec:method:accuracy}

In order to describe the accuracy of the \gls{dkd} as a method of estimating the true risk function \(\lambda\),
we use several accuracy measures.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Subsection: MISE
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{MISE}
\label{subsec:method:mise}

\Gls{mise} is a measure of the expected squared difference between an estimated risk function \gls{lambda_hat},
computed using the \gls{dkd}, and the true risk function \gls{lambda}.
\Gls{mise} allows for additional analysis by being broken down into the mean integraged bias and mean integrated variance.
It can also be easily approximated by cross-validation error.

For any given data sample, we can use the \gls{dkd} to compute the estimated risk function \gls{lambda_hat}.
We then integrate the squared error in the estimate over the plane to obtain the \gls{ise}.

\begin{equation}
    \mbox{ISE}(\hat{\lambda}) = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} \left( \hat{\lambda} - \lambda \right)^2 \diff{X_2} \diff{X_1}
\end{equation}

We can then compute the expected value of the \gls{ise} to obtain the \gls{mise}.

\begin{equation}
    \mbox{MISE} = \E [\mbox{ISE}]
\end{equation}

In our experiments, we run \(M\) monte carlo simulations, and approximate the \gls{mise} by taking the empirical average of the \glspl{ise}.

\begin{equation}
    \widetilde{\mbox{MISE}} = \frac{1}{M} \sum_{i=1}^{M} \mbox{ISE}_i
\end{equation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Subsection: MIAE
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{MIAE}
\label{subsec:method:miae}

\Gls{miae} is a measure of the expected absolute difference between an estimated risk function \gls{lambda_hat},
computed using the \gls{dkd}, and the true risk function \gls{lambda}.
\Gls{miae} differs from \gls{mise} by on the one hand providing a more intuitive comparison,
since we are comparing the absolute difference instead of the squared difference.
On the other hand, it lacks some of the nice mathematical properties of the \gls{mise}.

As we did in \autoref{subsec:method:mise}, for any given data sample we use the \gls{dkd} to compute the estimated risk function \gls{lambda_hat}.
We then integrate the absolute value of the error in the estimate over the plane to obtain the \gls{ise}.

\begin{equation}
    \mbox{IAE}(\hat{\lambda}) = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} \left| \hat{\lambda} - \lambda \right| \diff{X_2} \diff{X_1}
\end{equation}

We can then compute the expected value of the \gls{ise} to obtain the \gls{mise}.

\begin{equation}
    \mbox{MIAE} = \E [\mbox{IAE}]
\end{equation}

As above, we run \(M\) monte carlo simulations, and approximate the \gls{miae} by taking the empirical average of the \glspl{iae}.

\begin{equation}
    \widetilde{\mbox{MIAE}} = \frac{1}{M} \sum_{i=1}^{M} \mbox{IAE}_i
\end{equation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Subsection: Max error
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Supremum error}
\label{subsec:method:sup_error}

Whereas the previous two measures of accuracy describe how much the estimated intensity deviates from the truth over the whole plane,
the \gls{supremum error} looks at the worst case.
We define the \gls{supremum error} as follows:

\begin{equation}
    \mbox{supremum error}(\hat{\lambda}) = \sup_{\vec{x} \in \RS} {\left| \hat{\lambda}(\vec{x}) - \lambda(\vec{x}) \right|}
\end{equation}

As in the previous accuracy measures, we run \(M\) monte carlo simulations, and approximate the Max Error, or mean supremum error by taking the empirical average of the supremum errors.

\begin{equation}
    \widetilde{\mbox{Max Error}} = \frac{1}{M} \sum_{i=1}^{M} \mbox{supremum error}_i
\end{equation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Subsection: Peak bias and drift
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Peak bias and peak drift}
\label{subsec:method:peak_bias}

The next two accuracy measures compare the estimated risk function's accuracy in computing the peak.
The \gls{peak error} is difference between the maximum value of the \gls{dkd} estimate \gls{lambda_hat} and the maximum of the true risk function \gls{lambda}.
We denote by \gls{peak bias} the mean over the monte carlo simulations of the \gls{peak error}.
The \gls{peak bias} gives us a feel for how much the \gls{dkd} tends to over or underestimate the worst case of the true risk \gls{lambda}.

The second measure associated with the peak we call the \gls{peak drift}.
It is defined as the mean distance between the peak of \gls{lambda_hat} and \gls{lambda}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Subsection: Centroid bias and drift
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Centroid bias and peak drift}
\label{subsec:method:centroid_bias}

The final two accuracy measures also compare the estimated risk function's accuracy in computing the peak.
In fact, they are nearly identical to the preceding two accuracy measures.
However, unlike the \gls{peak error} and \gls{peak bias}, they do not use the exact peak of \gls{lambda_hat}.
Instead, they use the centroid and average value of \gls{lambda_hat} over the 5\% of the study area where \gls{lambda_hat} is highest.
We call the corresponding accuracy measures \gls{centroid bias} and \gls{centroid drift}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Section: experiment structure
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experiment structure}
\label{sec:method:experiment_structure}

In order to ensure repeatability of the experiements, we begin by setting the random number seed to the same fixed value (12).

The first step in each experimental run is to define the study area. 
The study area is always a 2-dimensional rectangle, with coordinates in the \(X_1\) and \(X_2\) directions set using the parameters \textit{x1.min}, \textit{x1.max}, \textit{x2.min}, and \textit{x2.max}.
The study area is further restricted by the \textit{buffer} parameter.

Next, a population is generated of size \textit{N.p}.
When the \textit{c1} and \textit{c2} parameters are given, the population is distributed according to the parameters above.
In particular, the distribution has bivariate normal shape with center (\textit{c1}, \textit{c2}),
standard deviations \textit{sigma1}, \textit{sigma2}, and correlation \textit{rho}.

Next, we adjust the incident rate function, \textit{incident\textunderscore rate} parameter, by scaling it so that the expected number of incidents is equal to the \textit{EN.i} parameter.
Assuming the expected number of incidents generate by \textit{incident\textunderscore rate} by itself is 1, we have

\[
    R(\vec{x}) = \mbox{EN.i}~\times~\mbox{incident\textunderscore rate}(\vec{x}) \text{,}
\]

and we call \(R(\vec{x}\) is the \textit{true incident rate} for the experiment.

\section{Verifying bandwidth selection dependency on size}

\section{Examining the effect of expected number of incidents on DKD accuracy}

\section{Examining sample size impact on DKD accuracy}

\section{Examining decay rate of the risk function on DKD accuracy}

\section{Examining decay rate of the population on DKD accuracy}

\section{Examining two peaks of the risk function}

\section{Examining non-uniform population distrbution}

